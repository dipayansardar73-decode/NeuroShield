# NeuroShield

**AI-powered Behavioral Anomaly Detection System for Insider Threat Detection**

*Built for Microsoft Imagine Cup 2026 - Cybersecurity Category*

## ğŸ“‹ Project Overview

NeuroShield is a cutting-edge behavioral anomaly detection platform that identifies insider threats in real-time using multi-agent AI orchestration. Organizations lose **$15B annually** to insider threats (data theft, sabotage, espionage). Traditional rule-based systems miss sophisticated behavioral anomalies. NeuroShield learns organizational culture patterns and detects deviations with AI-powered agents.

### Problem Statement
- âŒ Rule-based security systems miss sophisticated insider threats
- âŒ Reactive incident response (average dwell time: 207 days)
- âŒ No context-aware anomaly detection for organizational culture
- âŒ Manual correlation of multi-source security signals

### Our Solution
- âœ… ML-powered behavioral baseline learning (per user, role, time)
- âœ… Real-time anomaly detection across 7+ data sources
- âœ… Multi-agent orchestration for threat correlation
- âœ… Explainable AI with SHAP values
- âœ… <100ms inference latency
- âœ… Enterprise-grade scalability (1M+ events/sec)

## ğŸ—ï¸ Architecture Overview

```
Data Ingestion â†’ Stream Processing â†’ Feature Engineering â†’ Multi-Agent ML
    â†“                                                         â†“
Event Hubs     Stream Analytics    Azure ML Service    Risk Scoring Agent
(7+ sources)   (Real-time)         (PyTorch, XGBoost)  (Threat Correlation)
                                                         â†“
                                                    Alert & Response
                                                    (Dashboards, APIs)
```

## ğŸ“¦ Tech Stack

### Core ML/AI
- **Python 3.10+** - Core development language
- **PyTorch** - Deep learning (Graph Neural Networks)
- **Scikit-learn** - Classical ML (Isolation Forest, XGBoost, Random Forest)
- **SHAP** - Model explainability
- **Pandas/NumPy** - Data processing

### Cloud & Infrastructure
- **Azure Event Hubs** - Real-time data ingestion (1M+ events/sec)
- **Azure Stream Analytics** - Real-time feature engineering
- **Azure Machine Learning** - ML pipelines, model registry, inference endpoints
- **Azure Cosmos DB** - User profiles, baselines (NoSQL)
- **Azure Synapse** - Data warehouse (historical analysis)
- **Azure Container Registry** - Docker image management
- **Azure Kubernetes Service (AKS)** - Inference & API scaling

### Backend & API
- **FastAPI** - Async REST API with auto-documentation
- **Redis** - Caching & rate limiting
- **PostgreSQL** - Transactional data
- **Docker** - Containerization

### Frontend
- **React + TypeScript** - Web dashboard
- **D3.js / Plotly** - Data visualizations & graphs
- **Material-UI** - Component library
- **Vercel** - Deployment

### DevOps & Monitoring
- **GitHub Actions** - CI/CD pipelines
- **Terraform** - Infrastructure as Code
- **Azure Application Insights** - Monitoring & APM
- **Kubernetes** - Orchestration & scaling

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10+
- Docker & Docker Compose
- Git
- Azure CLI (for cloud deployments)
- Node.js 16+ (for frontend)

### Local Development Setup

```bash
# Clone the repository
git clone https://github.com/dipayansardar73-decode/NeuroShield.git
cd NeuroShield

# Create Python virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install development dependencies
pip install -r requirements-dev.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your Azure credentials

# Start Docker services (Event Hubs, Cosmos DB, etc.)
docker-compose up -d

# Run tests
pytest tests/

# Start development servers
# Terminal 1: Backend API
python -m uvicorn api.main:app --reload

# Terminal 2: Feature engineering service
python services/feature_engineering/main.py

# Terminal 3: Model inference service
python services/inference/main.py

# Terminal 4: Frontend (from frontend/ directory)
npm install && npm start
```

## ğŸ“ Project Structure

```
NeuroShield/
â”œâ”€â”€ data/                          # Data ingestion & processing
â”‚   â”œâ”€â”€ connectors/                # Log source connectors
â”‚   â”‚   â”œâ”€â”€ windows_eventlog.py
â”‚   â”‚   â”œâ”€â”€ network_logs.py
â”‚   â”‚   â”œâ”€â”€ email_metadata.py
â”‚   â”‚   â””â”€â”€ base_connector.py
â”‚   â”œâ”€â”€ parsers/                   # Log format parsers
â”‚   â”œâ”€â”€ validators/                # Data quality checks
â”‚   â””â”€â”€ generators/                # Synthetic data for testing
â”‚
â”œâ”€â”€ ml/                            # Machine Learning pipeline
â”‚   â”œâ”€â”€ features/                  # Feature engineering
â”‚   â”‚   â”œâ”€â”€ statistical.py
â”‚   â”‚   â”œâ”€â”€ temporal.py
â”‚   â”‚   â”œâ”€â”€ graph.py
â”‚   â”‚   â””â”€â”€ feature_store.py
â”‚   â”œâ”€â”€ models/                    # Model implementations
â”‚   â”‚   â”œâ”€â”€ baseline_models.py     # Isolation Forest, LOF, SVM
â”‚   â”‚   â”œâ”€â”€ supervised_models.py   # XGBoost, Random Forest
â”‚   â”‚   â”œâ”€â”€ gnn_model.py           # Graph Neural Network
â”‚   â”‚   â””â”€â”€ ensemble.py            # Model ensemble
â”‚   â”œâ”€â”€ training/                  # Training pipelines
â”‚   â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ hyperparameter_tuning.py
â”‚   â””â”€â”€ inference/                 # Real-time inference
â”‚       â”œâ”€â”€ predictor.py
â”‚       â””â”€â”€ explainability.py
â”‚
â”œâ”€â”€ services/                      # Microservices
â”‚   â”œâ”€â”€ feature_engineering/       # Real-time feature computation
â”‚   â”œâ”€â”€ inference/                 # Real-time ML inference
â”‚   â”œâ”€â”€ alert_orchestration/       # Multi-agent orchestration
â”‚   â””â”€â”€ response_automation/       # Automated response playbooks
â”‚
â”œâ”€â”€ api/                           # FastAPI backend
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ predictions.py
â”‚   â”‚   â”œâ”€â”€ alerts.py
â”‚   â”‚   â”œâ”€â”€ baselines.py
â”‚   â”‚   â””â”€â”€ admin.py
â”‚   â”œâ”€â”€ middleware/                # Auth, logging, monitoring
â”‚   â””â”€â”€ models/                    # Pydantic schemas
â”‚
â”œâ”€â”€ frontend/                      # React dashboard
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ stores/                # Redux/Zustand state
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ azure/                         # Azure ML & Infrastructure
â”‚   â”œâ”€â”€ ml_pipelines/              # Azure ML pipeline definitions
â”‚   â”œâ”€â”€ terraform/                 # Infrastructure as Code
â”‚   â””â”€â”€ kubernetes/                # K8s manifests
â”‚
â”œâ”€â”€ tests/                         # Comprehensive test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for EDA
â”‚   â”œâ”€â”€ 01_exploratory_data_analysis.ipynb
â”‚   â”œâ”€â”€ 02_model_comparison.ipynb
â”‚   â””â”€â”€ 03_feature_importance.ipynb
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ API_REFERENCE.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â””â”€â”€ CONTRIBUTING.md
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/                 # GitHub Actions CI/CD
â”‚       â”œâ”€â”€ test.yml
â”‚       â”œâ”€â”€ build.yml
â”‚       â””â”€â”€ deploy.yml
â”‚
â”œâ”€â”€ docker-compose.yml             # Local development services
â”œâ”€â”€ Dockerfile                     # Container image
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ requirements-dev.txt           # Development dependencies
â”œâ”€â”€ .env.example                   # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”‘ Key Features

### 1. **Multi-Source Data Ingestion**
- Windows Event Logs, Network/Proxy Logs, VPN Access
- Email Metadata, File Access Events, Endpoint Telemetry
- Cloud Activity (Azure, AWS), DNS Queries
- Real-time streaming via Azure Event Hubs

### 2. **Behavioral Baseline Learning**
- Per-user baselines (normal activity patterns)
- Role-based expectations
- Time-of-day and day-of-week seasonality
- Privilege escalation path mapping

### 3. **Anomaly Detection Ensemble**
- **Unsupervised**: Isolation Forest, Local Outlier Factor, One-Class SVM
- **Supervised**: XGBoost, Random Forest, LightGBM (with SHAP explainability)
- **Deep Learning**: Graph Neural Networks for relationship anomalies
- **Weighted Voting Ensemble** for robust predictions

### 4. **Multi-Agent Orchestration**
- **Behavior Analysis Agent** - Detects individual user anomalies
- **Risk Scoring Agent** - Quantifies threat severity
- **Threat Correlation Agent** - Links related incidents
- **Response Agent** - Recommends/executes response playbooks

### 5. **Real-Time Alerting**
- Dashboard with risk scorecards
- WebSocket streaming of live alerts
- Integration with Slack, Teams, SIEM systems
- Alert triage and feedback loop

### 6. **Explainability & Transparency**
- SHAP feature importance rankings
- Decision path visualization
- Model confidence scores
- Audit trail of all predictions

## ğŸ“Š Performance Targets

| Metric | Target |
|--------|--------|
| Detection Latency | <100ms (p95) |
| Throughput | 1M+ events/sec |
| Model AUC | >90% |
| Precision @ 10% False Positive Rate | >80% |
| Recall @ 10% False Positive Rate | >70% |
| Inference Cost | <$0.001 per prediction |

## ğŸ”„ Development Roadmap

### Phase 1: Foundation (Weeks 1-2)
- [ ] GitHub repo setup & CI/CD skeleton
- [ ] Data ingestion framework (3+ connectors)
- [ ] Schema validation & data quality checks

### Phase 2: ML Pipeline (Weeks 3-5)
- [ ] Feature engineering (50+ features)
- [ ] Synthetic dataset creation (~10K labeled events)
- [ ] 7+ models trained (Isolation Forest â†’ GNN)
- [ ] Ensemble model with >90% AUC

### Phase 3: Azure ML & Backend (Weeks 5-7)
- [ ] Azure ML pipelines & model registry
- [ ] Real-time inference endpoint (<100ms)
- [ ] FastAPI backend with auth & monitoring
- [ ] Cosmos DB user profiles & baselines

### Phase 4: Frontend & Integration (Weeks 7-8)
- [ ] React dashboard with real-time alerts
- [ ] Graph visualizations & investigation tools
- [ ] SIEM integrations (Splunk, Sentinel)
- [ ] Docker & Kubernetes deployment

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=. --cov-report=html

# Run specific test suite
pytest tests/unit/test_models.py -v

# Run integration tests
pytest tests/integration/ -v
```

## ğŸ“š Documentation

- [Architecture Deep Dive](docs/ARCHITECTURE.md)
- [API Reference](docs/API_REFERENCE.md)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [Model Documentation](docs/MODELS.md)
- [Contributing Guide](docs/CONTRIBUTING.md)

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

## ğŸ“œ License

MIT License - See LICENSE file for details

## ğŸ† Imagine Cup 2026

This project is submitted to Microsoft Imagine Cup 2026 - Cybersecurity Category.

**Team**: NeuroShield Development Team  
**Organization**: IIT Madras  
**Contact**: dipayansardar73@gmail.com

---

**Built with â¤ï¸ for enterprise security**
